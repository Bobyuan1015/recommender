{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original features: Index(['id', 'creator_id', 'created_time', 'updator_id', 'updated_time',\n",
      "       'delete_flag', 'news_title', 'news_subtitle', 'news_source',\n",
      "       'news_summary', 'img_url', 'liked_num', 'clap_num', 'recommend_flag',\n",
      "       'sort_no', 'publish_flag', 'news_detail', 'comment_num', 'read_num',\n",
      "       'news_type', 'follow_num', 'share_num', 'status', 'author',\n",
      "       'publish_time', 'video_url', 'pt'],\n",
      "      dtype='object')\n",
      "selected feauters: Index(['id', 'creator_id', 'created_time', 'updator_id', 'updated_time',\n",
      "       'delete_flag', 'news_title', 'news_subtitle', 'img_url', 'liked_num',\n",
      "       'clap_num', 'recommend_flag', 'news_type', 'follow_num', 'share_num',\n",
      "       'status', 'author', 'publish_time', 'video_url'],\n",
      "      dtype='object')\n",
      "No duplicated data in the frame， length= 2320\n",
      "id                False\n",
      "creator_id        False\n",
      "created_time      False\n",
      "updator_id         True\n",
      "updated_time      False\n",
      "delete_flag       False\n",
      "news_title         True\n",
      "news_subtitle      True\n",
      "img_url           False\n",
      "liked_num         False\n",
      "clap_num          False\n",
      "recommend_flag    False\n",
      "news_type         False\n",
      "follow_num        False\n",
      "share_num         False\n",
      "status            False\n",
      "author             True\n",
      "publish_time       True\n",
      "video_url          True\n",
      "dtype: bool\n",
      "[27, 96, 113, 114, 115, 116, 117, 119, 120, 121, 122, 126, 131, 132, 133, 134, 135, 136, 137, 138]\n",
      "[]\n",
      "filtered selected feauters: Index(['id', 'creator_id', 'created_time', 'updator_id', 'updated_time',\n",
      "       'delete_flag', 'news_title', 'news_subtitle', 'img_url', 'liked_num',\n",
      "       'clap_num', 'recommend_flag', 'news_type', 'follow_num', 'share_num',\n",
      "       'status', 'author', 'publish_time', 'video_url', 'update_year',\n",
      "       'update_month', 'update_week', 'update_day', 'update_timestamp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import time\n",
    "df=pd.read_csv(\"data/news0711.csv\",parse_dates=[2,4])\n",
    "# df.loc[:,['news_title','news_subtitle','news_detail']].to_csv('newsdetail.csv')\n",
    "print(\"original features:\",df.columns)\n",
    "newdf=df.loc[:,['id','creator_id','created_time','updator_id','updated_time','delete_flag','news_title','news_subtitle','img_url','liked_num','clap_num','recommend_flag','news_type','follow_num','share_num','status','author','publish_time','video_url']]\n",
    "print(\"selected feauters:\",newdf.columns)\n",
    "count=newdf['id'].value_counts()\n",
    "if count.values.sum() == len(count):\n",
    "    print(\"No duplicated data in the frame， length=\",len(count))\n",
    "else:\n",
    "    print(\"you need to go back for cleaning data \")\n",
    "print(newdf.isnull().any()) #判断那一列有空\n",
    "newdf['creator_id'].fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "dates = pd.to_datetime(df['updated_time'], format=\"%d/%m/%y %H:%M:%S+%H:%M\")\n",
    "# print(type(dates))\n",
    "newdf['update_year']=dates.dt.year\n",
    "newdf['update_month']=dates.dt.month\n",
    "newdf['update_week']=dates.dt.week\n",
    "newdf['update_day']=dates.dt.day\n",
    "# print(newdf['update_day'].head(5))\n",
    "# print(newdf['update_month'].head(5))\n",
    "# print(newdf['update_week'].head(5))\n",
    "# print(newdf['update_year'].head(5))\n",
    "\n",
    "newdf['updated_time']=newdf['updated_time'].apply(lambda x: x.strftime(\"%d/%m/%y %H:%M:%S\"))\n",
    "# print(\"update:\",newdf['updated_time'].head(5),\" type=\",type(newdf['updated_time'][1]))\n",
    "newdf['update_timestamp'] = newdf['updated_time'].apply(lambda x:time.mktime(time.strptime(x,\"%d/%m/%y %H:%M:%S\")))              \n",
    "# print(newdf['update_timestamp'].head(5))\n",
    "def minMaxNormalization(x):\n",
    "    return DataFrame({\"update_timestamp\":np.rint([1000*(float(i)-min(x))/float(max(x)-min(x)) for i in x])})\n",
    "newdf['update_timestamp']=minMaxNormalization(newdf['update_timestamp'])\n",
    "\n",
    "def check_deletedFlag():    \n",
    "    flags =newdf['delete_flag'].tolist()\n",
    "    removeIndexs=[]\n",
    "    for index, flag in enumerate(flags):\n",
    "        if flag == 1:\n",
    "            removeIndexs.append(index)\n",
    "    print(removeIndexs[:20])\n",
    "check_deletedFlag()        \n",
    "newdf.drop(newdf.index[removeIndexs],inplace=True)\n",
    "check_deletedFlag() \n",
    "# print(newdf['update_timestamp'].head(5))\n",
    "print(\"filtered selected feauters:\",newdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 96, 113, 114, 115, 116, 117, 119, 120, 121, 122, 126, 131, 132, 133, 134, 135, 136, 137, 138]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# newdf['updated_time'][1].strftime(\"%d/%m/%y %H:%M:%S+%H:%M\"))\n",
    "# time.mktime(time.strptime(newdf['updated_time'][1].strftime(\"%d/%m/%y %H:%M:%S+%H:%M\"）\"%d/%m/%y %H:%M:%S+%H:%M\"))            \n",
    "            \n",
    "# dates = dates.unique()\n",
    "# start_date = dates[0]\n",
    "# end_date = dates[-1]\n",
    "# print(\"Start date: \", start_date)\n",
    "# print(\"End Date: \", end_date)\n",
    "# date_range = pd.date_range(start_date, end_date).values\n",
    "# assert(all(dates == date_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # newdf['creator_id']=newdf['creator_id'].apply(lambda x:1 if isinstance(x,str) else x)\n",
    "    #\n",
    "    # newdf['name'].fillna(0,inplace=True)\n",
    "    # newdf['name']=newdf['name'].replace({'\\\\N': 0})\n",
    "    # newdf['name']=newdf['name'].apply(lambda x:1 if isinstance(x,str) else x)\n",
    "    #\n",
    "    # newdf['sex'].fillna(0,inplace=True)\n",
    "    # newdf['sex']=newdf['sex'].replace({'\\\\N': 0})\n",
    "    #\n",
    "    # newdf['head_url'].fillna(0,inplace=True)\n",
    "    # newdf['head_url']=newdf['head_url'].replace({'\\\\N': 0})\n",
    "    # newdf['head_url']=newdf['head_url'].apply(lambda x:1 if isinstance(x,str) else x)\n",
    "    #\n",
    "    # # newdf['region']=newdf['region'].apply(lambda x:0 if not isinstance(x,str) else x)\"数字也是字符串，不好处理\"\n",
    "    # newdf['region'].fillna('0',inplace=True)\n",
    "    # newdf['region']=newdf['region'].replace({'\\\\N': '0'})\n",
    "    #\n",
    "    # def decode_region(x):\n",
    "    #     listedArray = list(x)\n",
    "    #     dict_address={}\n",
    "    #     for index,ad in enumerate(np.unique(x)):\n",
    "    #         dict_address[ad]=index\n",
    "    #     for address_index, address in  enumerate(listedArray):\n",
    "    #         listedArray[address_index]=dict_address[address]\n",
    "    #     return DataFrame({'region':listedArray})\n",
    "    # newdf['region']=decode_region(newdf.region.values)\n",
    "    #\n",
    "    # #\n",
    "    # #\n",
    "    #\n",
    "    # # # newdf['region']=newdf['region'].apply(lambda x:1 if isinstance(x,str) else x)\n",
    "    # #\n",
    "    # newdf['autograph'].fillna(0,inplace=True)\n",
    "    # newdf['autograph']=newdf['autograph'].replace({'\\\\N': 0})\n",
    "    # newdf['autograph']=newdf['autograph'].apply(lambda x:1 if isinstance(x,str) else x)\n",
    "    #\n",
    "    # newdf['integral'].fillna(0,inplace=True)\n",
    "    # newdf['integral']=newdf['integral'].replace({'\\\\N': 0})\n",
    "    #\n",
    "    # newdf['is_big_v'].fillna(0,inplace=True)\n",
    "    # newdf['is_big_v']=newdf['is_big_v'].replace({'\\\\N': 0})\n",
    "    #\n",
    "    # newdf['is_first_login'].fillna(0,inplace=True)\n",
    "    # newdf['is_first_login']=newdf['is_first_login'].replace({'\\\\N': 0})\n",
    "    # newdf['is_first_login']=newdf['is_first_login'].astype('int')\n",
    "    #\n",
    "    #\n",
    "    # print(newdf.isnull().any()) #判断那一列有空\n",
    "    #\n",
    "# newdf.loc[:,['news_title','news_subtitle']].to_csv(\"clean_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
